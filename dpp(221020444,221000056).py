# -*- coding: utf-8 -*-
"""DPP(221020444,221000056)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1awAvZSsBbyNKeqOUjT_IhnhV1eNF05e4

Importing Libraries
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder

students_dataset = pd.read_csv('/content/Student.csv')

df=pd.read_csv("Student.csv")
df.head(10)

students_dataset.shape

for i in students_dataset:
  print(i)

students_dataset.describe()

students_dataset.info()

df.dropna().head(10)

students_dataset.columns

"""Histogram"""

df["NrSiblings"].plot(kind = 'hist')

"""Mean Imputation"""

df["NrSiblings"] = df["NrSiblings"].fillna(int(df["NrSiblings"].mean()))
df

"""Histogram after Mean Imputation"""

df["NrSiblings"].plot(kind = 'hist')

"""Histogram"""

df["ReadingScore"].plot(kind = 'hist')

"""Mode Imputation"""

column_m1 = df['ReadingScore'].mode()
print(column_m1)
df['ReadingScore']=df['ReadingScore'].fillna(column_m1)
df.head(10)

"""Histogram after Median Imputation"""

df["ReadingScore"].plot(kind = 'hist')

"""Scatter Plot"""

df.plot(kind = 'scatter', x = 'WritingScore', y= 'MathScore')
plt.show()

"""Median Imputation"""

column_mn = df['MathScore'].median()
print(column_mn)
df['MathScore']=df['MathScore'].fillna(column_mn)
df.head(10)

"""Scaler plot after Medain Imputation"""

df.plot(kind = 'scatter', x = 'MathScore', y= 'WritingScore')
plt.show()

"""Bar Graph"""

column_to_plot = 'ReadingScore'
bin_edges = [0, 25, 50, 75, 100]
bin_labels = ['0-5', '6-10', '11-15', '16-20']
df['binned_' + column_to_plot] = pd.cut(df[column_to_plot], bins=bin_edges, labels=bin_labels)
data_counts = df['binned_' + column_to_plot].value_counts()
data_counts = data_counts.loc[bin_labels]
plt.figure(figsize=(10, 6))
data_counts.plot(kind='bar', color='skyblue')
plt.title('Bar Graph for Binned ' + column_to_plot)
plt.xlabel('Count')
plt.ylabel('Bins')
plt.xticks(rotation=45)
plt.show()

"""mode Imputation"""

column_m= df['ReadingScore'].mode()
print(column_m)
df['ReadingScore']=df['ReadingScore'].fillna(column_m)
df

"""Bar Graph after mode imputation"""

column_to_plot = 'ReadingScore'
bin_edges = [0, 25, 50, 75, 100]
bin_labels = ['0-5', '6-10', '11-15', '16-20']
df['binned_' + column_to_plot] = pd.cut(df[column_to_plot], bins=bin_edges, labels=bin_labels)
data_counts = df['binned_' + column_to_plot].value_counts()
data_counts = data_counts.loc[bin_labels]
plt.figure(figsize=(10, 6))
data_counts.plot(kind='bar', color='skyblue')
plt.title('Bar Graph for Binned ' + column_to_plot)
plt.xlabel('Count')
plt.ylabel('Bins')
plt.xticks(rotation=45)
plt.show()

"""Histogram Types(Singleton,Equal width)



"""

column_to_plot = 'MathScore'
unique_values = df[column_to_plot].value_counts()
plt.figure(figsize=(10, 6))
unique_values.plot(kind='bar', color='blue')
plt.xlabel(column_to_plot)
plt.ylabel('Count')
plt.title(f'Singleton Histogram for {column_to_plot}')
plt.tight_layout()
plt.show()

"""Equal Width Histogram"""

num_bins = 10
data_min = df['MathScore'].min()
data_max = df['MathScore'].max()
bin_edges = np.linspace(data_min, data_max, num=num_bins+1)
plt.figure(figsize=(10, 6))
plt.hist(df['MathScore'], bins=bin_edges, color='lightgreen', edgecolor='black')
plt.xlabel('MathScore')
plt.ylabel('Frequency')
plt.title(f'Equal Width Histogram for {column_to_plot}')
plt.tight_layout()
plt.show()

"""
EOD(end of distrubtion) Imputation"""

df['WritingScore'].hist()

eod_value = df['WritingScore'].mean() + 3 *df['MathScore'].std()
print(eod_value)
df['WritingScore']=df['WritingScore'].fillna(eod_value)
df

df['WritingScore'].hist()

"""Mean Imputation"""

column_mean =df['WritingScore'].mean()
print(column_mean)
df['WritingScore']=df['WritingScore'].fillna(int(column_mean))
df

"""Handling Missing Categorical Data

before applying Frequncy Category Imputation
"""

df

"""Frequncy categorical Imputation"""

x = df['EthnicGroup'].mode()[0]
df['EthnicGroup']=df['EthnicGroup'].fillna(x)
print(x)
df

""" before Removing Duplicates histogram"""

df['ParentMaritalStatus'].hist()

"""Removing Duplicate"""

column_to_check_duplicates = 'ParentMaritalStatus'
n8_df=df.drop_duplicates(subset=column_to_check_duplicates)
n8_df

"""Histogram after removing duplicates"""

n8_df['ParentMaritalStatus'].hist()

"""Encoding Methods

One Hot Encoding
"""

df=pd.get_dummies(df['NrSiblings'])
df.head(10)

"""**Label** Encoding

Discretization

before applying
 Equal width Discretization
"""

df['WritingScore'].plot(kind='hist')

"""After equal width Discritzation"""

import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_csv('/content/Student.csv')
column_to_discretize = 'MathScore'
num_bins = 5
df['discretized_' + column_to_discretize] = pd.cut(df[column_to_discretize], bins=num_bins)
bin_counts = df['discretized_' + column_to_discretize].value_counts().sort_index()
plt.bar(bin_counts.index.astype(str), bin_counts.values,)
plt.title('Histogram of Discretized ' + column_to_discretize)
plt.xlabel('Discretized ' + column_to_discretize)
plt.ylabel('Frequency')
plt.xticks(rotation=45)
plt.show()

"""Outlier Handling"""

column_to_plot = 'MathScore'
plt.boxplot(df[column_to_plot], vert=True)
plt.title('Box Plot of ' + column_to_plot)
plt.xlabel(column_to_plot)
plt.show()
column_data = df[column_to_plot]
q1 = column_data.quantile(0.25)
q3 = column_data.quantile(0.75)
iqr = q3 - q1
lower_bound = q1 - 1.5 * iqr
upper_bound = q3 + 1.5 * iqr
outliers = column_data[(column_data < lower_bound) | (column_data > upper_bound)]
print("Outliers:")
print(outliers)
print("Median : ")
print(df[column_to_plot].median())

"""Heat map"""

correlation_matrix = df.corr()
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='Reds', linewidths=0.5)
plt.title('Correlation Heatmap')
plt.show()

"""Normalizattion"""

df = pd.read_csv('Student.csv')
skewness = df['WritingScore'].skew()
if skewness > 0:
    print("The dataset is right-skewed (positively skewed).")
elif skewness < 0:
    print("The dataset is left-skewed (negatively skewed).")
else:
    print("The dataset is approximately normally distributed.")

"""DecisionTreeClassifier"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
df = pd.read_csv('Student.csv')
target_column = 'Gender'
feature_columns = ['MathScore', 'WritingScore']
X = df[feature_columns]
y = df[target_column]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
clf = DecisionTreeClassifier(random_state=42)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy}')
report = classification_report(y_test, y_pred)
print(report)

"""CCA(Complete Case Analysis)"""

df.dropna()
df

df['NrSiblings'].fillna(1000,inplace=True)
df